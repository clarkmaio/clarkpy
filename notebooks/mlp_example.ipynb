{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to use NeuralNetModel class\n",
    "Just a simple notebook to show how easy is to use my NeuralNetModel class.\n",
    "\n",
    "In few lines of code you can:\n",
    "- Build a neural network\n",
    "- Train it (sklearn like)\n",
    "- Fine tune it freezing some layers\n",
    "\n",
    "The class is built in such a way that all these operations can be done in a **single line of code**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcb95a610870a4e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Fix numpy and torch seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from ml.neuralnet import NeuralNetModel\n",
    "from ml.neuralnet.utils.visualisation import plot_weights\n",
    "from torch.nn import ReLU, Identity"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "187f95c96ce0f43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The dataset (borign part)\n",
    "For this example I will build a simple dataset. We will focus on a non linear regression problem.\n",
    "\n",
    "Two datasets will be built:\n",
    "- The first one will be used to train the neural network\n",
    "- The second one will be used to fine tune the neural network. Namely the first layers will be frozen and only the last layers will be updated on the new data. \n",
    "\n",
    "Both dataset will consist in a target and a single feature (let's keep it simple).\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b74cfe69b5645d30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build data\n",
    "N_train = 1000\n",
    "X = np.linspace(0, 10, N_train).reshape(-1, 1)\n",
    "y = 1 * X * np.sin(X) + 1.1*np.random.normal(0, 2, N_train).reshape(-1, 1)\n",
    "\n",
    "N_finetune = 100\n",
    "X_finetune = np.linspace(0, 10, N_finetune).reshape(-1, 1)\n",
    "y_finetune = 1 * X_finetune * np.cos(X_finetune) + 0.3*np.random.normal(0, 2, N_finetune).reshape(-1, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7333f0467e7b6c7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "plt.scatter(X, y, alpha=0.5, color='blue', edgecolors='black', label='Original data')\n",
    "plt.scatter(X_finetune, y_finetune, alpha=0.5, color='red', edgecolors='black', label='Finetune data', marker='s')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.grid(linestyle=':')\n",
    "plt.title('The datasets', fontweight='bold')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "52150ca4953b7fb5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build the neural network (interesting part!)\n",
    "The neural network is built using the NeuralNetModel class.\n",
    "\n",
    "Using this class you can build only full connected sequential models.\n",
    "\n",
    "With the inputs `layers_units`, `activations`, `dropout_layers` you can define the architecture of the neural network.\n",
    "With the remaining parameters: `epochs`, `batch_size`, `learning_rate`, `optimizer`  you can define the training procedure.\n",
    "\n",
    "Keep in mind that you can update `epochs`, `batch_size` parameters also when calling the `fit` method.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61da0abfa4b5cec7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build model\n",
    "LAYER_UNITS = [10, 10, 10, 1]\n",
    "HIDDEN_ACTIVATION = [ReLU(), ReLU(), ReLU(), Identity()]\n",
    "\n",
    "neuralnet = NeuralNetModel(layers_units=LAYER_UNITS,\n",
    "                           activations=HIDDEN_ACTIVATION,\n",
    "                           dropout_layers=[0, 0, 0, 0],\n",
    "                           epochs=800, batch_size=1000,\n",
    "                           learning_rate=0.01, optimizer='Adam',\n",
    "                           loss='mae',\n",
    "                           verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9df2185208cb923e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train model\n",
    "neuralnet.fit(X, y, shuffle=True)\n",
    "pred = neuralnet.predict(X)\n",
    "\n",
    "named_parameters_train = deepcopy(list(neuralnet.mlp.named_parameters()))\n",
    "loss_history_fit = neuralnet.loss_history"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ffb5cdeae6ea97eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine tune the neural network in one line! (another interesting part!)\n",
    "Once you have trained the neural network you can fine tune it on new data.\n",
    "\n",
    "You can use `fine_tune` method to do so. With the parameter `freeze_layer_index` you can specify which layers you want to freeze in term of layer index (namely **which layers will not be updated**).\n",
    "\n",
    "After `fine_tune` method is called alle the layers are unfreezed.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34544936c516297a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fine tune on new data\n",
    "neuralnet.fine_tune(X=X_finetune, y=y_finetune, freeze_layer_index=[0, 1], epochs=600, shuffle=True)\n",
    "pred_finetune = neuralnet.predict(X_finetune)\n",
    "\n",
    "named_parameters_finetune = deepcopy(list(neuralnet.mlp.named_parameters()))\n",
    "loss_history_finetune = neuralnet.loss_history"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f9581ca5e089e73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's see the results (plots are always interesting)\n",
    "We can look at the regression results toghether with the loss history of the two training procedures."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8832497f73e73a25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, ax = plt.subplots(2, 1, figsize = (7, 7))\n",
    "\n",
    "ax[0].scatter(X, y, alpha=0.5, color='blue', edgecolors='black', label='Original data')\n",
    "ax[0].plot(X, pred, alpha=1, color='orange', linestyle='--', linewidth=2, label='Prediction train')\n",
    "ax[0].scatter(X_finetune, y_finetune, alpha=0.5, color='red', edgecolors='black', label='New data', marker='s')\n",
    "ax[0].plot(X_finetune, pred_finetune, alpha=1, color='black', linestyle='--', linewidth=2, label='Prediction finetune')\n",
    "ax[0].set_xlabel('X')\n",
    "ax[0].set_ylabel('y')\n",
    "ax[0].grid(linestyle=':')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(loss_history_fit.index, loss_history_fit, label='Loss train', color='blue')\n",
    "ax[1].plot(loss_history_finetune.index, loss_history_finetune, label='Loss finetune', color='red')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].grid(linestyle=':')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "256c4d89047b3fb5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Did the fine tuning work?\n",
    "But how the weights changed after the fine tuning?\n",
    "Let's see it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a16652e44a889afe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### First two layers: these should be the same before and after fine tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbfe6101559a7cc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_weights_parameters = [(name, param) for name, param in named_parameters_train if 'weight' in name.lower()]\n",
    "plot_weights(train_weights_parameters[:2], annot=True, annot_kws={'size': 8}, subplot_title=True, title='First 2 layers before fine tuning')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "89908c5d39b413bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "finetune_weights_parameters = [(name, param) for name, param in named_parameters_finetune if 'weight' in name.lower()]\n",
    "plot_weights(finetune_weights_parameters[:2], annot=True, annot_kws={'size': 8}, subplot_title=True, title='First 2 layers after fine tuning')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9680ed6c224f9faa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Last two layers: these should be different before and after fine tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2be96139c4844a88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_weights_parameters = [(name, param) for name, param in named_parameters_train if 'weight' in name.lower()]\n",
    "plot_weights(train_weights_parameters[-2:], annot=True, annot_kws={'size': 7}, subplot_title=True, title='Weights before fine tuning')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d0ba84b0baf6775f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "finetune_weights_parameters = [(name, param) for name, param in named_parameters_finetune if 'weight' in name.lower()]\n",
    "plot_weights(finetune_weights_parameters[-2:], annot=True, annot_kws={'size': 7}, subplot_title=True, title='Weights after fine tuning')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dd24a2da03fad926"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
